from bs4 import BeautifulSoup
import requests
import pandas as pd
url = base_url.format(page_num)

try:
    response = requests.get(url)
    response.raise_for_status()  # Raise error for bad status
except requests.exceptions.RequestException as e:
    print(f"Request failed on page {page_num}: {e}")
    continue

soup = BeautifulSoup(response.text, "html.parser")

# Find table safely
hockey_table = soup.find("table", class_="table")

if hockey_table is None:
    print(f"No table found on page {page_num}")
    continue

# Extract headers only once
if page_num == 1:
    table_titles = hockey_table.find_all("th")
    columns = [title.text.strip() for title in table_titles]

# Extract all rows and skip header
table_rows = hockey_table.find_all("tr")[1:]

for row in table_rows:
    cells = row.find_all("td")
    row_data = [cell.text.strip() for cell in cells]
    all_data.append(row_data)
